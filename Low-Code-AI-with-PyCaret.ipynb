{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Code ML Workshop with PyCaret\n",
    "\n",
    "### Vanderlei Munhoz - IBM Hybrid Cloud Build Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# About PyCaret\n",
    "\n",
    "PyCaret is an open source, low-code machine learning library in Python that aims to **reduce cycle time from hypothesis to insights**.\n",
    "\n",
    "Reference: https://pycaret.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Installing Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pycaret shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Loading Datasets\n",
    "\n",
    "1. PyCaret has sample datasets that can be loaded with the **pycaret.datasets.get_data** method.\n",
    "2. All modules in PyCaret can work directly with pandas Dataframe. It can consume the dataframe, Irrespective of how it is loaded in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the PyCaret sample data repository\n",
    "from pycaret.datasets import get_data\n",
    "\n",
    "dataset = get_data('credit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data using Pandas:\n",
    "import pandas as pd\n",
    "\n",
    "!wget https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/credit.csv\n",
    "dataset = pd.read_csv('./credit.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Analyzing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using standard Pandas methods on the dataframes:\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using standard Pandas methods on the dataframes:\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Plotting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using SNS for plotting:\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(dataset[['SEX', 'AGE', 'EDUCATION', 'default']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Visualizing Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib and sns for plotting correlation between variables:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "corr = dataset.corr()\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask, 1)] = True\n",
    "\n",
    "a = sns.heatmap(corr, mask=mask, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Dataset Splitting for Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training & testing according to the **frac** value. Use **random_state** for reproducibility\n",
    "train_data = dataset.sample(frac=0.8, random_state=2130912)\n",
    "test_data = dataset.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset DataFrame index values\n",
    "train_data.reset_index(inplace=True, drop=True)\n",
    "test_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# PyCaret Setup\n",
    "\n",
    "Before calling any PyCaret function, first we need to run the **setup** method.\n",
    "\n",
    "This function initializes the training environment and creates the transformation pipeline. \n",
    "\n",
    "It takes two mandatory parameters: **data** and **target**. All the other parameters are optional.\n",
    "\n",
    "Reference: https://pycaret.readthedocs.io/en/latest/api/classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "clf = setup(\n",
    "    data=train_data, \n",
    "    target='default', \n",
    "    session_id=123,\n",
    "    normalize=True,\n",
    "    normalize_method='robust',\n",
    "    pca=False,  # If set to True, dimensionality reduction is performed\n",
    "    pca_method='linear',  # 'linear' performs the Single Value Decomposition\n",
    "    pca_components=0.8,  # Retain 80% of the original features\n",
    "    remove_multicollinearity=True,  # remove features with inter-correlations higher than the defined threshold below\n",
    "    multicollinearity_threshold=0.92,\n",
    "    remove_outliers=False,\n",
    "    outliers_threshold=0.05,\n",
    "    fix_imbalance=True,  # When set to True, SMOTE (Synthetic Minority Over-sampling Technique) is applied by default to create synthetic datapoints for minority class\n",
    "    fold_strategy='stratifiedkfold',\n",
    "    fold_shuffle=True,\n",
    "    fold=5,  # Number of folds for cross validation\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Train and Compare classifiers automatically with PyCaret\n",
    "\n",
    "**Accuracy**: Fraction of correct predictions (accuracy alone doesn't tell the full story when you're working with a class-imbalanced data set)\n",
    "\n",
    "**AUC**: [0, 1.0] - Bigger is better (derived from ROC). Reference: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\n",
    "\n",
    "**Recall**: Answers the question: \"What proportion of actual positives was identified correctly?\"\n",
    "\n",
    "**Precision**: Answers the question: \"What proportion of positive identifications was actually correct?\"\n",
    "\n",
    "**F1**: F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.\n",
    "\n",
    "**Kappa**: Better for multi-class and imbalanced class problems.\n",
    "\n",
    "**MCC**: Matthew's Correlation Coefficient (measures the quality of binary classificators). The coefficient takes into account true and false positives and negatives. Can also be used for imbalanced problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = compare_models(n_select=5, exclude=['xgboost', 'lightgbm', 'gbc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The top5 variable is a list with the best 5 models regarding the chosen metric\n",
    "print(top5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(top5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(top5[0], 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(top5[0], 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference for plotting models: https://pycaret.org/plot-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Tuning the best model parameters automatically with PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If we want to tune the model for a different metric (ex: F1 score):\n",
    "top_model_tuned_for_AUC = tune_model(top5[0], optimize='AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can check the different generated hyperparameters for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(top_model_tuned_for_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(top_model_tuned_for_AUC, 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(top_model_tuned_for_AUC, 'parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Blending Models with PyCaret\n",
    "\n",
    "Blending models is a method of ensembling which uses consensus among estimators to generate final predictions. The idea behind blending is to combine different machine learning algorithms and use a majority vote or the average predicted probabilities in case of classification to predict the final outcome. Blending models in PyCaret is as simple as writing blend_models. This function can be used to blend specific trained models that can be passed using estimator_list parameter within blend_models or if no list is passed, it will use all the models in model library. In case of Classification, method parameter can be used to define ‘soft‘ or ‘hard‘ where soft uses predicted probabilities for voting and hard uses predicted labels. This functions returns a table with k-fold cross validated scores of common evaluation metrics along with trained model object. The evaluation metrics used are:\n",
    "\n",
    "    Classification: Accuracy, AUC, Recall, Precision, F1, Kappa, MCC\n",
    "    Regression: MAE, MSE, RMSE, R2, RMSLE, MAPE\n",
    "\n",
    "Reference: https://pycaret.org/blend-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll train a `blended` model based on the top5 models trained before\n",
    "top5_models_blended = blend_models(estimator_list=top5, method='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(top5_models_blended, 'class_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Ensembling models with PyCaret\n",
    "\n",
    "Ensembling a trained model is as simple as writing ensemble_model. It takes only one mandatory parameter i.e. the trained model object. This functions returns a table with k-fold cross validated scores of common evaluation metrics along with trained model object. The evaluation metrics used are:\n",
    "\n",
    "    Classification: Accuracy, AUC, Recall, Precision, F1, Kappa, MCC\n",
    "    Regression: MAE, MSE, RMSE, R2, RMSLE, MAPE\n",
    "\n",
    "Reference: https://pycaret.org/ensemble-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging:\n",
    "\n",
    "Bagging, also known as Bootstrap aggregating, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. \n",
    "\n",
    "It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. \n",
    "\n",
    "Bagging is a special case of the model averaging approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a bagging classifier on the top model trained before\n",
    "bagged_top0 = ensemble_model(top5[0], method='Bagging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(bagged_top0, 'class_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting:\n",
    "\n",
    "Boosting is an ensemble meta-algorithm for primarily reducing bias and variance in supervised learning. \n",
    "\n",
    "Boosting is in the family of machine learning algorithms that convert weak learners to strong ones. \n",
    "\n",
    "A weak learner is defined to be a classifier that is only slightly correlated with the true classification (it can label examples better than random guessing). \n",
    "\n",
    "In contrast, a strong learner is a classifier that is arbitrarily well-correlated with the true classification."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " # !!! WARNING -- TAKES A VERY LONG TIME TO TRAIN !!!\n",
    "\n",
    "# Train a boosted classifier on the top model trained before\n",
    "boosted_top0 = ensemble_model(top5[0], method='Boosting', n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 + GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
